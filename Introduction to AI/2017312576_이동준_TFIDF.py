# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sddj8uIKdVlJhUhAqzGDG0TaTmPW9JwR
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.tokenize import word_tokenize
import json
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

with open('drive/My Drive/Colab Notebooks/bbc_articles.json') as json_file:
  json_data = json.load(json_file)

themes = list(json_data.keys())
articles = []
for theme in themes:
  articles = articles + json_data[theme]

POS_corpus = list()

for article in articles:
  pos_token = nltk.pos_tag(word_tokenize(article))
  POS_corpus.append(' '.join([t[0] for t in pos_token if t[1] in ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']]))

tfidfvect = TfidfVectorizer()
tfidfvect.fit_transform(POS_corpus)
result = tfidfvect.transform(POS_corpus).toarray().tolist()


with open('drive/My Drive/Colab Notebooks/2017312576_이동준_TFIDF.txt','w') as f:
  for i in range(len(themes)):
    for j in range(len(json_data[themes[i]])):
      article = articles[j]
      f.write('('+themes[i]+str(j+1)+")\n")
      for TF_IDF in result[i*100 + j]:
        f.write(str(TF_IDF)+"\t") # 여기서 반올림?
      f.write("\n\n")